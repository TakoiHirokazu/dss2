{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b8bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================\n",
    "# Library\n",
    "# ==================\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from contextlib import contextmanager\n",
    "import logging\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "import time\n",
    "import feather\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from logger import setup_logger, LOGGER\n",
    "from trainer import train_lgbm\n",
    "from util_tool import reduce_mem_usage\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ac9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Constant\n",
    "# ==================\n",
    "ex = \"013\"\n",
    "TRAIN_PATH = \"../input/train.csv\"\n",
    "TEST_PATH = \"../input/test.csv\"\n",
    "USER_PATH = \"../input/user_x_anime.csv\"\n",
    "SUB_PATH = \"../input/sample_submission.csv\"\n",
    "SAVE_OOF_PATH = f\"../output/exp/ex{ex}_oof.npy\"\n",
    "SAVE_TEST_SUB_PATH = f\"../output/exp/ex{ex}_test_sub.csv\"\n",
    "LOGGER_PATH = f\"../output/exp/ex_{ex}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88554e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============\n",
    "# Settings\n",
    "# ===============\n",
    "\n",
    "SEED = 0\n",
    "N_SPLITS = 5\n",
    "SHUFFLE = True\n",
    "LGBM_PARAMS = {'num_leaves': 32,\n",
    "               'min_data_in_leaf': 64,\n",
    "               'objective': 'regression',\n",
    "               'max_depth': -1,\n",
    "               'learning_rate': 0.05,\n",
    "               \"boosting\": \"gbdt\",\n",
    "               \"bagging_freq\": 1,\n",
    "               \"bagging_fraction\": 0.8,\n",
    "               \"bagging_seed\": SEED,\n",
    "               \"verbosity\": -1,\n",
    "              'reg_alpha': 0.1,\n",
    "              'reg_lambda': 0.3,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'metric':\"rmse\",\n",
    "              'num_threads':32,\n",
    "         }\n",
    "\n",
    "LGBM_FIT_PARAMS = {\n",
    "    'num_boost_round': 5000,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'verbose_eval': 1000,\n",
    "}\n",
    "\n",
    "load_feature = [\"../output/fe/fe001.feather\",\n",
    "                \"../output/fe/fe002.feather\",\n",
    "                \"../output/fe/fe003.feather\",\n",
    "                \"../output/fe/fe004.feather\",\n",
    "                \"../output/fe/fe005.feather\",\n",
    "                \"../output/fe/fe006.feather\",\n",
    "                \"../output/fe/fe007.feather\",\n",
    "                \"../output/fe/fe009.feather\",\n",
    "                \"../output/fe/fe011.feather\",\n",
    "                \"../output/fe/fe012.feather\",\n",
    "                \"../output/fe/fe013.feather\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389fdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Function\n",
    "# ====================\n",
    "\n",
    "def calc_loss(y_true, y_pred):\n",
    "    return  np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield \n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e640ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 07:55:47,094 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOGGER = logging.getLogger()\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "setup_logger(out_file=LOGGER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7739222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Main\n",
    "# ====================\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "y = train_raw[\"Score\"]\n",
    "df = None\n",
    "for i in load_feature:\n",
    "    if df is not None:\n",
    "        _df = pd.read_feather(i)\n",
    "        df  = pd.concat([df, _df], axis=1)\n",
    "    else:\n",
    "        df = pd.read_feather(i)\n",
    "train = df.iloc[:len(train_raw)]\n",
    "test = df.iloc[len(train_raw):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bb7034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "train: 4000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttraining's rmse: 0.1183\tvalid_1's rmse: 0.329195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 07:56:00,144 - INFO - Fold0:CV=0.3291954281138874\n",
      "2021-08-19 07:56:00,162 - INFO - [fold 0] done in 7 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "train: 4000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttraining's rmse: 0.0390482\tvalid_1's rmse: 0.319782\n",
      "[2000]\ttraining's rmse: 0.0173374\tvalid_1's rmse: 0.31881\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3731/3935930235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLGBM_FIT_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0mcalc_importances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/working/src/trainer.py\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(X_train, y_train, X_valid, y_valid, X_test, categorical_features, feature_name, fold_id, lgb_params, fit_params, loss_func, calc_importances)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2643\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2645\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2646\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with timer(\"lightgbm\"):\n",
    "    kf = KFold(n_splits=N_SPLITS,random_state=SEED, shuffle=SHUFFLE)\n",
    "    y_oof = np.empty([len(train),])\n",
    "    y_test = []\n",
    "    drop_cols = []\n",
    "    features = list(train.columns)\n",
    "    features = [i for i in features if i not in drop_cols]\n",
    "    feature_importances = pd.DataFrame()\n",
    "    categorical_features = []\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train,y)):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        with timer(f\"fold {fold}\"):\n",
    "            x_train, y_train = train.iloc[train_idx][features], y.iloc[train_idx]\n",
    "            x_val, y_val =train.iloc[valid_idx][features], y.iloc[valid_idx]\n",
    "            print(\"train:\",len(x_train))\n",
    "\n",
    "            y_pred_valid, y_pred_test, valid_loss, importances, best_iter,_ = train_lgbm(\n",
    "                        x_train, y_train, x_val, y_val,test[features],\n",
    "                        categorical_features=categorical_features,\n",
    "                        feature_name=features,\n",
    "                        fold_id=fold,\n",
    "                        lgb_params=LGBM_PARAMS,\n",
    "                        fit_params=LGBM_FIT_PARAMS,\n",
    "                        loss_func=calc_loss,\n",
    "                        calc_importances=True\n",
    "                    )\n",
    "\n",
    "            y_oof[valid_idx] = y_pred_valid\n",
    "            score = calc_loss(y[valid_idx], y_pred_valid)\n",
    "            LOGGER.info(f'Fold{fold}:CV={score}')\n",
    "            y_test.append(y_pred_test)\n",
    "            feature_importances = pd.concat([feature_importances, importances], axis=0, sort=False)\n",
    "\n",
    "    score = calc_loss(y, y_oof)\n",
    "    np.save(SAVE_OOF_PATH, y_oof)\n",
    "    LOGGER.info(f'CV={score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sub =  np.mean(y_test,axis=0)\n",
    "sub = pd.read_csv(SUB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Score\"] = y_test_sub\n",
    "sub.to_csv(SAVE_TEST_SUB_PATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb58cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.groupby(by=\"feature\").mean().sort_values(by=\"gain\",ascending=False).iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad35dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
